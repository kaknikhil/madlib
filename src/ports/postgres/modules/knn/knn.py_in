# coding=utf-8
#
# Licensed to the Apache Software Foundation (ASF) under one
# or more contributor license agreements.  See the NOTICE file
# distributed with this work for additional information
# regarding copyright ownership.  The ASF licenses this file
# to you under the Apache License, Version 2.0 (the
# "License"); you may not use this file except in compliance
# with the License.  You may obtain a copy of the License at
#
#   http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing,
# software distributed under the License is distributed on an
# "AS IS" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
# KIND, either express or implied.  See the License for the
# specific language governing permissions and limitations
# under the License.

"""
@file knn.py_in

@brief knn: Driver functions

@namespace knn

"""

import plpy
from utilities.validate_args import input_tbl_valid, output_tbl_valid
from utilities.validate_args import cols_in_tbl_valid
from utilities.validate_args import is_col_array
from utilities.validate_args import array_col_has_no_null
from utilities.validate_args import get_expr_type
from utilities.utilities import unique_string
from utilities.control import MinWarning


def knn_validate_src(schema_madlib, point_source, point_column_name, point_id,
                     label_column_name, test_source, test_column_name,
                     test_id, output_table, k, output_neighbors, fn_dist,
                     **kwargs):
    input_tbl_valid(point_source, 'kNN')
    input_tbl_valid(test_source, 'kNN')
    output_tbl_valid(output_table, 'kNN')
    if label_column_name is not None and label_column_name != '':
        cols_in_tbl_valid(
            point_source,
            (label_column_name,
             point_column_name),
            'kNN')
    cols_in_tbl_valid(point_source, (point_column_name, point_id), 'kNN')
    cols_in_tbl_valid(test_source, (test_column_name, test_id), 'kNN')

    if not is_col_array(point_source, point_column_name):
        plpy.error("kNN Error: Feature column '{0}' in train table is not"
                   " an array.").format(point_column_name)
    if not is_col_array(test_source, test_column_name):
        plpy.error("kNN Error: Feature column '{0}' in test table is not"
                   " an array.").format(test_column_name)

    if not array_col_has_no_null(point_source, point_column_name):
        plpy.error("kNN Error: Feature column '{0}' in train table has some"
                   " NULL values.".format(point_column_name))
    if not array_col_has_no_null(test_source, test_column_name):
        plpy.error("kNN Error: Feature column '{0}' in test table has some"
                   " NULL values.".format(test_column_name))

    if k is None:
        k = 1
    if k <= 0:
        plpy.error("kNN Error: k={0} is an invalid value, must be greater"
                   "than 0.".format(k))
    bound = plpy.execute("SELECT {k} <= count(*) AS bound FROM {tbl}".
                         format(k=k, tbl=point_source))[0]['bound']
    if not bound:
        plpy.error("kNN Error: k={0} is greater than number of rows in"
                   " training table.".format(k))

    if label_column_name is not None and label_column_name != '':
        col_type = get_expr_type(label_column_name, point_source).lower()
        if col_type not in ['integer', 'double precision', 'float', 'boolean']:
            plpy.error("kNN error: Data type '{0}' is not a valid type for"
                       " column '{1}' in table '{2}'.".
                       format(col_type, label_column_name, point_source))

    col_type_test = get_expr_type(test_id, test_source).lower()
    if col_type_test not in ['integer']:
        plpy.error("kNN Error: Data type '{0}' is not a valid type for"
                   " column '{1}' in table '{2}'.".
                   format(col_type_test, test_id, test_source))

    if fn_dist:
        fn_dist = fn_dist.lower().strip()
        dist_functions = set([schema_madlib + dist for dist in
                              ('.dist_norm1', '.dist_norm2', '.squared_dist_norm2', '.dist_angle', '.dist_tanimoto')])

        is_invalid_func = plpy.execute(
            """select prorettype != 'DOUBLE PRECISION'::regtype
                OR proisagg = TRUE AS OUTPUT from pg_proc where
                oid='{fn_dist}(DOUBLE PRECISION[], DOUBLE PRECISION[])'::regprocedure;
                """.format(**locals()))[0]['output']

        if is_invalid_func or fn_dist not in dist_functions:
            plpy.error(
                "KNN error: Distance function has wrong signature or is not a simple function.")

    return k
# ------------------------------------------------------------------------------


def knn(schema_madlib, point_source, point_column_name, point_id,
        label_column_name, test_source, test_column_name, test_id, output_table,
        k, output_neighbors, fn_dist):
    """
        KNN function to find the K Nearest neighbours
        Args:
            @param schema_madlib        Name of the Madlib Schema
            @param point_source         Training data table
            @param point_column_name    Name of the column with training data
            @param point_id             Name of the column having ids of data
                                        point in train data table
                                        points.
            @param label_column_name    Name of the column with labels/values
                                        of training data points.
            @param test_source          Name of the table containing the test
                                        data points.
            @param test_column_name     Name of the column with testing data
                                        points.
            @param test_id              Name of the column having ids of data
                                        points in test data table.
            @param output_table         Name of the table to store final
                                        results.
            @param k                    default: 1. Number of nearest
                                        neighbors to consider
            @output_neighbours          Outputs the list of k-nearest neighbors
                                        that were used in the voting/averaging.
            @param fn_dist              Distance metrics function. Default is
                                        squared_dist_norm2. Following functions
                                        are supported :
                                        dist_norm1 , dist_norm2,squared_dist_norm2,
                                        dist_angle , dist_tanimoto
                                        Or user defined function with signature
                                        DOUBLE PRECISION[] x, DOUBLE PRECISION[] y -> DOUBLE PRECISION
    """
    with MinWarning('warning'):
        k_val = knn_validate_src(schema_madlib, point_source,
                                 point_column_name, point_id, label_column_name,
                                 test_source, test_column_name, test_id,
                                 output_table, k, output_neighbors, fn_dist)

        x_temp_table = unique_string(desp='x_temp_table')
        y_temp_table = unique_string(desp='y_temp_table')
        label_col_temp = unique_string(desp='label_col_temp')
        test_id_temp = unique_string(desp='test_id_temp')

        if output_neighbors is None:
            output_neighbors = True

        if not fn_dist:
            fn_dist = schema_madlib + '.squared_dist_norm2'

        fn_dist = fn_dist.lower().strip()
        interim_table = unique_string(desp='interim_table')

        pred_out = ""
        knn_neighbors = ""
        label_out = ""
        cast_to_int = ""

        if output_neighbors:
            knn_neighbors = (", array_agg(knn_temp.train_id ORDER BY "
                             "knn_temp.dist ASC) AS k_nearest_neighbours ")
        if label_column_name:
            is_classification = False
            label_column_type = get_expr_type(
                label_column_name, point_source).lower()
            if label_column_type in ['boolean', 'integer', 'text']:
                is_classification = True
                cast_to_int = '::INTEGER'

            pred_out = ", avg({label_col_temp})".format(**locals())
            if is_classification:
                pred_out = (", {schema_madlib}.mode({label_col_temp})"
                            ).format(**locals())
            pred_out += " AS prediction"
            label_out = (", train.{label_column_name}{cast_to_int}"
                         " AS {label_col_temp}").format(**locals())

        if not label_column_name and not output_neighbors:

            plpy.error("kNN error: Either label_column_name or "
                       "output_neighbors has to be non-NULL.")

        plpy.execute("""
            CREATE TEMP TABLE {interim_table} AS
                SELECT * FROM (
                    SELECT row_number() over
                            (partition by {test_id_temp} order by dist) AS r,
                            {x_temp_table}.*
                    FROM (
                        SELECT test.{test_id} AS {test_id_temp} ,
                            train.{point_id} as train_id ,
                            {fn_dist}(
                                train.{point_column_name},
                                test.{test_column_name})
                            AS dist {label_out}
                            FROM {point_source} AS train,
                                {test_source} AS test
                        ) {x_temp_table}
                    ) {y_temp_table}
            WHERE {y_temp_table}.r <= {k_val}
            """.format(**locals()))

        plpy.execute(
            """
            CREATE TABLE {output_table} AS
                SELECT {test_id_temp} AS id, {test_column_name}
                    {pred_out}
                    {knn_neighbors}
                FROM pg_temp.{interim_table} AS knn_temp
                    JOIN
                    {test_source} AS knn_test ON
                    knn_temp.{test_id_temp} = knn_test.{test_id}
                GROUP BY {test_id_temp} , {test_column_name}
            """.format(**locals()))

        plpy.execute("DROP TABLE IF EXISTS {0}".format(interim_table))
        return

def knn_help(schema_madlib, message, **kwargs):
    """
    Help function for knn

    Args:
        @param schema_madlib
        @param message: string, Help message string
        @param kwargs

    Returns:
        String. Help/usage information
    """
    if message is not None and \
            message.lower() in ("usage", "help", "?"):
        help_string = """
-----------------------------------------------------------------------
                            USAGE
-----------------------------------------------------------------------
SELECT {schema_madlib}.knn(
    point_source,       -- Training data table having training features as vector column and labels
    point_column_name,  -- Name of column having feature vectors in training data table
    point_id,           -- Name of column having feature vector Ids in train data table
    label_column_name,  -- Name of column having actual label/vlaue for corresponding feature vector in training data table
    test_source,        -- Test data table having features as vector column. Id of features is mandatory
    test_column_name,   -- Name of column having feature vectors in test data table
    test_id,     -- Name of column having feature vector Ids in test data table
    output_table,       -- Name of output table
    k,                  -- value of k. Default will go as 1
    output_neighbors    -- Outputs the list of k-nearest neighbors that were used in the voting/averaging.
    fn_dist             -- The name of the function to use to calculate the distance from a data point to a centroid.
    );

-----------------------------------------------------------------------
                            OUTPUT
-----------------------------------------------------------------------
The output of the KNN module is a table with the following columns:

id                  The ids of test data points.
test_column_name    The test data points.
prediction          The output of KNN- label in case of classification, average value in case of regression.
k_nearest_neighbours The list of k-nearest neighbors that were used in the voting/averaging.
"""
    else:
        if message is not None and \
                message.lower() in ("example", "examples"):
            help_string = """
----------------------------------------------------------------------------
                                EXAMPLES
----------------------------------------------------------------------------
--  Prepare some training data for classification:
DROP TABLE IF EXISTS knn_train_data;
CREATE TABLE knn_train_data (
                    id integer,
                    data integer[],
                    label integer  -- Integer label means for classification
                    );
INSERT INTO knn_train_data VALUES
(1, '{{1,1}}', 1),
(2, '{{2,2}}', 1),
(3, '{{3,3}}', 1),
(4, '{{4,4}}', 1),
(5, '{{4,5}}', 1),
(6, '{{20,50}}', 0),
(7, '{{10,31}}', 0),
(8, '{{81,13}}', 0),
(9, '{{1,111}}', 0);

--  Prepare some training data for regression:
DROP TABLE IF EXISTS knn_train_data_reg;
CREATE TABLE knn_train_data_reg (
                    id integer,
                    data integer[],
                    label float  -- Float label means for regression
                    );
INSERT INTO knn_train_data_reg VALUES
(1, '{{1,1}}', 1.0),
(2, '{{2,2}}', 1.0),
(3, '{{3,3}}', 1.0),
(4, '{{4,4}}', 1.0),
(5, '{{4,5}}', 1.0),
(6, '{{20,50}}', 0.0),
(7, '{{10,31}}', 0.0),
(8, '{{81,13}}', 0.0),
(9, '{{1,111}}', 0.0);

--  Prepare some testing data:
DROP TABLE IF EXISTS knn_test_data;
CREATE TABLE knn_test_data (
                    id integer,
                    data integer[]
                    );
INSERT INTO knn_test_data VALUES
(1, '{{2,1}}'),
(2, '{{2,6}}'),
(3, '{{15,40}}'),
(4, '{{12,1}}'),
(5, '{{2,90}}'),
(6, '{{50,45}}');

--  Run KNN for classification:
DROP TABLE IF EXISTS knn_result_classification;
SELECT * FROM {schema_madlib}.knn(
                'knn_train_data',      -- Table of training data
                'data',                -- Col name of training data
                'id',                  -- Col name of id in train data
                'label',               -- Training labels
                'knn_test_data',       -- Table of test data
                'data',                -- Col name of test data
                'id',                  -- Col name of id in test data
                'knn_result_classification',  -- Output table
                 3,                    -- Number of nearest neighbors
                 True,                 -- True to list nearest-neighbors by id
                 'madlib.squared_dist_norm2' -- Distance function
                );
SELECT * from knn_result_classification ORDER BY id;

Note that the nearest neighbors are sorted from closest
to furthest from the corresponding test point.

--  Run KNN for regression:
DROP TABLE IF EXISTS knn_result_regression;
SELECT * FROM {schema_madlib}.knn(
                'knn_train_data_reg',  -- Table of training data
                'data',                -- Col name of training data
                'id',                  -- Col Name of id in train data
                'label',               -- Training labels
                'knn_test_data',       -- Table of test data
                'data',                -- Col name of test data
                'id',                  -- Col name of id in test data
                'knn_result_regression',  -- Output table
                 3,                    -- Number of nearest neighbors
                True,                  -- True to list nearest-neighbors by id
                'madlib.dist_norm2'    -- Distance function
                );
SELECT * FROM knn_result_regression ORDER BY id;

--  List nearest neighbors only, without doing classification
or regression:
DROP TABLE IF EXISTS knn_result_list_neighbors;
SELECT * FROM {schema_madlib}.knn(
                'knn_train_data_reg',  -- Table of training data
                'data',                -- Col name of training data
                'id',                  -- Col Name of id in train data
                NULL,                  -- NULL training labels means just list neighbors
                'knn_test_data',       -- Table of test data
                'data',                -- Col name of test data
                'id',                  -- Col name of id in test data
                'knn_result_list_neighbors', -- Output table
                3                      -- Number of nearest neighbors
                );
SELECT * FROM knn_result_list_neighbors ORDER BY id;
"""
        else:
            help_string = """
----------------------------------------------------------------------------
                                SUMMARY
----------------------------------------------------------------------------
k-Nearest Neighbors is a method for finding k closest points to a given data
point in terms of a given metric. Its input consist of data points as features
from testing examples. For a given k, it looks for k closest points in
training set for each of the data points in test set. Algorithm generates one
output per testing example. The output of KNN depends on the type of task:
For Classification, the output is majority vote of the classes of the k
nearest data points. The testing example gets assigned the most popular class
among nearest neighbors. For Regression, the output is average of the values
of k nearest neighbors of the given testing example.
--
For an overview on usage, run:
SELECT {schema_madlib}.knn('usage');

For some examples, run:
SELECT {schema_madlib}.knn('example')
--
"""

    return help_string.format(schema_madlib=schema_madlib)
# ------------------------------------------------------------------------------

